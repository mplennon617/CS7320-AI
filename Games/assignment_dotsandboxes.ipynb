{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Dots and Boxes\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undegraduates 100, graduate students 110\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play the game Dots and Boxes:\n",
    "\n",
    "> \"Dots and Boxes is a pencil-and-paper game for two players. The game starts with an empty grid of dots. Usually two players take turns adding a single horizontal or vertical line between two unjoined adjacent dots. A player who completes the fourth side of a 1x1 box earns one point and takes another turn. A point is typically recorded by placing a mark that identifies the player in the box, such as an initial. The game ends when no more lines can be placed. The winner is the player with the most points. The board may be of any size grid.\" (see [Dots and Boxes on Wikipedia](https://en.wikipedia.org/wiki/Dots_and_Boxes))\n",
    "\n",
    "You can play Dots and Boxes [here](https://www.math.ucla.edu/~tom/Games/dots&boxes.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [10 point]\n",
    "\n",
    "Define the components of the search problem associated with this game:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model\n",
    "* Test for the terminal state\n",
    "* Utility for terminal states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "* Initial state: Empty board containing an 2D array of dots of size $m*n$. No lines are connected and no boxes are formed. It is player Max's turn.\n",
    "* Actions: Place one line on available edge between two dots \n",
    "* Transition model: f(prev_state): action x prev_state = {all instances of prev_state with one additional line placed on a previously available edge (and potentially an additional box filled)} Swap turns IFF no new box was formed.\n",
    "* Test for the terminal state: Player Max or Player Min has formed more than $\\lfloor\\frac{(m-1)(n-1)}{2}\\rfloor+1$ boxes OR every possible line on the board has been filled by a player.\n",
    "* Utility for terminal states: $Boxes(Max) - Boxes(Min)$, where $Boxes(p)$ is the number of boxes owned by player $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the state space? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer **(FINISH!!!!!!!!!):** \n",
    "State Space Estimation: # possible line configurations * # possible initial configurations.\n",
    "\n",
    "**possible line configurations for board size n x n:**\n",
    "(|{empty, your line, opponent line}| ^ ((n-1)(n))*2) -- Horizontal and vertical (2) orientatations -- each orientation has n \"rows\", with n-1 lines available to be placed per row. Order of the lines matters, so we perform a permutation calculation.\n",
    "\n",
    "e.g. for board size 5 x 5: # line configurations would be 3^40.\n",
    "\n",
    "**possible initialed configurations for board size n x n:** \n",
    "(|{no initial, your initial, opponent initial}| ^ (n^2 - n)) -- At minimum, n boxes MUST be empty, so we exclude them from the possible state calculation. Then the remaining n^2 - n boxes can initialed by a player or not. Order of the initials matter, so we perform a permutation calculation.\n",
    "\n",
    "Full estimation: 3^(((n-1)(n))*2) * 3^(n^2-n). The line estimation is an accurate permutation. However, for initials, there is only one scenario in which the number of initials is 9 (that is, initials filled by each layer along the diagonal). While this is a valid state, our agent will never try to achieve this strategy, so it's likely in practice that we will have to worry with far fewer states (say, only 6 or 7 initialized boxes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the game tree that minimax search will go through? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [30 point]\n",
    "\n",
    "You need to think about a data structure to represent the board meaning he placed lines and who finished what box. There are many options. Let's represent the board using a simple dictionary where `n` and `m` represents the number of dots horizontaly and vertically, respectively. Everybody needs to use the same representation so we can let agents play against each other later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n': 4, 'm': 4, ('h', 1, 1): True, ('v', 1, 1): True}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def empty_board(m = 4,n = 4):\n",
    "    return {\n",
    "    'n': n,  ### hoizontal dots\n",
    "    'm': m   ### vertical dots\n",
    "    }\n",
    "\n",
    "board = {\n",
    "    'n': 4,  ### hoizontal dots\n",
    "    'm': 4   ### vertical dots\n",
    "}\n",
    "\n",
    "def draw_line(board, orientation, row, col):\n",
    "    \"\"\"\n",
    "    Place a line on an exiting board.\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    board: dict\n",
    "        the board\n",
    "    orientation: str\n",
    "        either 'h' or 'v' for horizontal or vertical\n",
    "    row, col: int\n",
    "        index of the starting dot for the line (starting with 0)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if orientation not in ['h', 'v']:\n",
    "        return False\n",
    "        \n",
    "    if row < 0 or col < 0:\n",
    "        return False\n",
    "        \n",
    "    if row >= board['n'] + (orientation == 'v') or col >= board['m'] + (orientation == 'h'):\n",
    "        return False\n",
    "        \n",
    "    if (orientation, row, col) in board:\n",
    "        return False\n",
    "            \n",
    "    board[(orientation, row, col)] = True\n",
    "    return True\n",
    "    \n",
    "\n",
    "print(draw_line(board, \"h\", 1, 1))\n",
    "print(draw_line(board, \"v\", 1, 1))\n",
    "\n",
    "# this hould not work\n",
    "print(draw_line(board, \"h\", 1, 1))\n",
    "\n",
    "board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to display the board. **Bonus point: Post your visualization code with an example output to the discussion board. The best visualization will earn you bonus participation points in this class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "def show_board(board, show_results=False):\n",
    "    n = board['n']  # Rows\n",
    "    m = board['m']  # Columns\n",
    "   \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(-0.5, m-0.5)\n",
    "    ax.set_ylim(-0.5, n-0.5)\n",
    "   \n",
    "    # Draw dots\n",
    "    for row in range(n):\n",
    "        for col in range(m):\n",
    "            if (row, col) in board:\n",
    "                ax.scatter(col, row, s=100, marker='o', color='black')\n",
    "            else:\n",
    "                ax.scatter(col, row, s=100, marker='o', color='black')\n",
    "     \n",
    "    # Draw lines\n",
    "    for line in board:\n",
    "        # print(line)\n",
    "        if line != 'n' and line != 'm' and line != -1 and line != 1:\n",
    "            # print(line)\n",
    "            if len(line) > 2:\n",
    "                # Draw Horizontal line\n",
    "                if line[0] == 'h':\n",
    "                    #print(\"for line ('h'\",line[1],line[2],\"), plot line from X=\",line[2]+1,\"to\",line[2]+2,\"and Y=\",n-line[1],\"to\",n-line[1])\n",
    "                    #l = mlines.Line2D([line[2]+1,line[2]+2], [n-line[1],n-line[1]], color='black')\n",
    "                    l = mlines.Line2D([line[2],line[2]+1], [n-line[1]-1,n-line[1]-1], color='black')\n",
    "                    ax.add_line(l)\n",
    "                # Draw Vertical line\n",
    "                elif line[0] == 'v':\n",
    "                    #print(\"for line ('v'\",line[1],line[2],\"), plot line from X=\",line[2]+1,\"to\",line[2]+1,\"and Y=\",n-line[1],\"to\",n-line[1]-1)                    \n",
    "                    #l = mlines.Line2D([line[2]+1,line[2]+1], [n-line[1],n-line[1]-1], color='black')\n",
    "                    l = mlines.Line2D([line[2],line[2]], [n-line[1]-2,n-line[1]-1], color='black')\n",
    "                    ax.add_line(l)\n",
    "   \n",
    "    # Check for boxes\n",
    "    # Boxes are stored in board with (row, col) as key and player (1 or -1) as value\n",
    "    # eg: board[(3, 1)] = 1 -> player 1 has a box with top left vertex at (3, 1)\n",
    "    for box in board:\n",
    "        if box != 'n' and box != 'm' and box != -1 and box != 1:\n",
    "            if len(box) == 2:\n",
    "                if board[(box[0], box[1])] == 1:\n",
    "                    ax.add_patch(plt.Rectangle((box[1], n - box[0] - 1), 1, -1, color='b'))\n",
    "                    #print(\"blue box at point (\",box[1],\",\",n - box[0] - 1,\")\")\n",
    "                else:\n",
    "                    ax.add_patch(plt.Rectangle((box[1], n - box[0] - 1), 1, -1, color='r'))\n",
    "                    #print(\"red box at point (\",box[1],\",\",n - box[0] - 1,\")\")\n",
    "   \n",
    "    # Print results  \n",
    "    if (show_results):\n",
    "        print('Results:')\n",
    "        print('         -1:', board[-1])\n",
    "        print('          1:', board[1])\n",
    "   \n",
    "    # Set up plot to start at (1, 1)\n",
    "    x = []\n",
    "    y = []\n",
    "    for row in range(board['n']):\n",
    "        # x.append(row)\n",
    "        x.append(row+1)\n",
    "    for col in range(board['m']):\n",
    "        # y.append(col)\n",
    "        y.append(col+1)\n",
    "    default_x_ticks = range(len(x))\n",
    "    plt.xticks(default_x_ticks, x)\n",
    "    default_y_ticks = range(len(y))\n",
    "    plt.yticks(default_y_ticks, y)\n",
    "   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement helper functions for:\n",
    "\n",
    "* The transition model $result(s, a)$.\n",
    "* The utility function $utility(s)$.\n",
    "* Check for terminal states $terminal(s)$.\n",
    "* A check for available actions in each state $actions(s)$.\n",
    "\n",
    "__Notes:__\n",
    "* Make sure that all these functions work with boards of different sizes (number of columns and rows as stored in the board).\n",
    "* The result function evaluates if the player closed a box and needs to store that information on the board. Add elements of the form `(row,col): player` to the board dictionary. `row` and `col` are the coordinates for the box and `player` is +1 or -1 representing the player. For example `(0,0): -1` means that the top-left box belongs to the other player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to return all the boxes in a board owned by a player.\n",
    "# Each box is a tuple of the form: (Box location, owner)\n",
    "def get_boxes(board):\n",
    "\n",
    "    boxes = []\n",
    "    for key in board.keys():\n",
    "        if (isinstance(key,tuple) and len(key) == 2):\n",
    "            boxes.append(key)\n",
    "\n",
    "    return boxes\n",
    "\n",
    "# Helper function to return all the lines in the board.\n",
    "def get_lines(board):\n",
    "    lines = []\n",
    "    for key in board.keys():\n",
    "        if (isinstance(key,tuple) and len(key) == 3):\n",
    "            lines.append(key)\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referencing this paper as I go:\n",
    "# https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/viewFile/5126/5218#:~:text=Dots%2DAnd%2DBoxes%20is%20impartial,pieces%20of%20a%20certain%20color.\n",
    "\n",
    "def result(board,orientation,row,col,player, DEBUG = 0):\n",
    "    \"\"\"\n",
    "    Evaluates the state of the board, detecting and filling any unfilled boxes.\n",
    "    Only searches for unfilled boxes based on the most recent line placed \n",
    "    (determined by params orientation, row, and col).\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    board: dict\n",
    "        the board\n",
    "    orientation: str\n",
    "        either 'h' or 'v' for horizontal or vertical\n",
    "    row, col: int\n",
    "        index of the starting dot for the line (starting with 0)\n",
    "    player\n",
    "        whether player max (1) or player min (-1) placed the line\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    new_board = board.copy()\n",
    "\n",
    "    # Place the line.\n",
    "    new_board[(orientation,row,col)] = True\n",
    "\n",
    "    # Check if boxes are formed, and place them.\n",
    "    if (orientation == 'h'):\n",
    "        # Horizontal case -- check if a box formed above (if possible)\n",
    "        if (row > 0):\n",
    "            if (('h',row-1,col) in new_board and \n",
    "                ('v',row-1,col) in new_board and\n",
    "                ('v',row-1,col+1) in new_board ):\n",
    "                \n",
    "                if DEBUG >= 1: print(\"new box added above -- (\",row-1,\",\",col,\")\")\n",
    "                new_board[(row-1,col)] = player\n",
    "        # Horizontal case -- check if a box formed below (if possible)\n",
    "        if (row < new_board['n'] - 1):\n",
    "            if (('h',row+1,col) in new_board and \n",
    "            ('v',row,col) in new_board and\n",
    "            ('v',row,col+1) in new_board):\n",
    "\n",
    "                if DEBUG >= 1: print(\"new box added below -- (\",row,\",\",col,\")\")          \n",
    "                new_board[(row,col)] = player\n",
    "\n",
    "    elif (orientation == 'v'):\n",
    "        # Vertical case -- check if a box formed to the left (if possible)\n",
    "        if (col > 0):\n",
    "            if (('v',row,col-1) in new_board and \n",
    "            ('h',row,col-1) in new_board and\n",
    "            ('h',row+1,col-1) in new_board):\n",
    "                \n",
    "                if DEBUG >= 1: print(\"new box added left -- (\",row,\",\",col-1,\")\")   \n",
    "                new_board[(row,col-1)] = player\n",
    "\n",
    "        # Vertical case -- check if a box formed to the right (if possible)\n",
    "        if (row < new_board['m'] - 1):\n",
    "            if (('v',row,col+1) in new_board and \n",
    "            ('h',row,col) in new_board and\n",
    "            ('h',row+1,col) in new_board):\n",
    "\n",
    "                if DEBUG >= 1: print(\"new box added right -- (\",row,\",\",col,\")\")                  \n",
    "                new_board[(row,col)] = player\n",
    "\n",
    "    #print(\"BOARD UPDATED\")\n",
    "    #show_board(board)\n",
    "\n",
    "    return new_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Ratio of boxes Max owns to boxes Min owns.\n",
    "def utility(board):\n",
    "\n",
    "    DEBUG = 0\n",
    "\n",
    "    utility = 0\n",
    "\n",
    "    # Who owns what box?\n",
    "    # Calculate utility by calculating Max - Min.\n",
    "    for box in get_boxes(board):\n",
    "        if DEBUG >= 2: print(box,\"belongs to\",board[box])\n",
    "        if (board[box] == 1):\n",
    "            if DEBUG >= 2: print(\"+\",end='')\n",
    "            utility += 1\n",
    "        elif (board[box] == -1):\n",
    "            if DEBUG >= 2: print(\"-\",end='')\n",
    "            utility -= 1\n",
    "\n",
    "    if DEBUG >= 1: print(\"Utility calculated for a board: \",utility)\n",
    "\n",
    "    # TODO: WE WANT TO ADD SOME REGULARIZATION TO THIS FUNCTION.\n",
    "    return utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_win(board):\n",
    "    \"\"\"\n",
    "    Helper function to check whether a player has placed enough boxes to guarantee a win \n",
    "    (i.e. guarantee ownership of more boxes than the other)\n",
    "    \"\"\"\n",
    "    boxes = get_boxes(board)\n",
    "\n",
    "    win_threshold = (board['m']-1)*(board['n']-1)//2 + 1\n",
    "\n",
    "    # At any point, if it's determined that max or min has obtained 'win_threshold' boxes\n",
    "    # Then return that player as the winner.\n",
    "    # Otherwise, return 0 (No winner yet).\n",
    "    min_cnt = 0\n",
    "    max_cnt = 0\n",
    "    for box in boxes:\n",
    "        if board[box] == 1:\n",
    "            max_cnt += 1\n",
    "        elif board[box] == -1:\n",
    "            min_cnt += 1\n",
    "        \n",
    "        if max_cnt >= win_threshold:\n",
    "            return 1\n",
    "        if min_cnt >= win_threshold:\n",
    "            return -1\n",
    "\n",
    "\n",
    "    return 0\n",
    "    \n",
    "def check_board_full(board):\n",
    "    \"\"\"\n",
    "    Helper function to check whether the board is completely filled with\n",
    "    lines (i.e. whether there are no more possible moves to make).\n",
    "    \"\"\"\n",
    "\n",
    "    m = board['m']\n",
    "    n = board['n']\n",
    "    \n",
    "    return len(get_lines(board)) >= m*(n-1) + n*(m-1)\n",
    "\n",
    "def terminal(board):\n",
    "    \"\"\"\n",
    "    Terminal function -- checks whether a given board state is a terminal\n",
    "    node.\n",
    "    \"\"\"\n",
    "    return check_win(board) or check_board_full(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions(board):\n",
    "    \"\"\"\n",
    "    Actions function -- returns positions of all possible lines the player can place.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(board['n']):\n",
    "        for j in range(board['m']):\n",
    "            if (i == board['n']-1 and j == board['m']-1):\n",
    "                continue\n",
    "            if (('h',i,j) not in board and j != board['m']-1):\n",
    "                res.append(('h',i,j))\n",
    "            if (('v',i,j) not in board and i != board['n']-1):\n",
    "                res.append(('v',i,j))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
    "\n",
    "`def random_player(board, player = None): ...`\n",
    "\n",
    "The argument `player` is used for agents that do not store what side they are playing. The value passed on by the environment should be 1 ot -1 for playerred and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "def random_player(board, player=None, order_fun = None):\n",
    "    possible_actions = actions(board)\n",
    "    return possible_actions[np.random.choice(len(possible_actions),1)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
    "\n",
    "How often does each player win? Is the result expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue (1) Wins: 340\n",
      "Red (-1) Wins: 660\n",
      "Draws: 0\n"
     ]
    }
   ],
   "source": [
    "def switch_player(player, pfun1, pfun2):\n",
    "    if player == 1:\n",
    "        return -1, pfun2\n",
    "    elif player == -1:\n",
    "        return 1, pfun1\n",
    "\n",
    "# Your code/ answer goes here.\n",
    "def play(pfun1, pfun2, N = 1, show_final_board = False, start_board = empty_board()):\n",
    "    \"\"\"Let two agents play each other N times. red starts. red and yellow are agent functions that \n",
    "    get the board as the percept and return their next action.\n",
    "    \n",
    "    Code Adopted and modified from tictactoe_interactive.ipynb.\n",
    "    \"\"\"\n",
    "    results = {1: 0, -1: 0, 0: 0}\n",
    "    \n",
    "    for i in range(N):\n",
    "        board = start_board.copy()\n",
    "        player, fun = 1, pfun1\n",
    "        \n",
    "        while True:\n",
    "            action = fun(board, player)\n",
    "            board = result(board, action[0], action[1], action[2], player)\n",
    "            win = check_win(board)   # returns the 'n' if the game is not done.\n",
    "            if win != 0:\n",
    "                results[win] += 1\n",
    "                if show_final_board: \n",
    "                    print(\"Final board:\")\n",
    "                    show_board(board)\n",
    "                break\n",
    "\n",
    "            if check_board_full(board):\n",
    "                results[0] += 1\n",
    "                break\n",
    "            \n",
    "            player, fun = switch_player(player, pfun1, pfun2)   \n",
    "    \n",
    "    return results\n",
    "\n",
    "results = play(random_player, random_player, N = 1000,show_final_board=False)\n",
    "print(\"Blue (1) Wins:\",results[1])\n",
    "print(\"Red (-1) Wins:\",results[-1])\n",
    "print(\"Draws:\",results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final board:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final board:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final board:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final board:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final board:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue (1) Wins: 1\n",
      "Red (-1) Wins: 4\n"
     ]
    }
   ],
   "source": [
    "# Demo: Play 5 games and display the final boards.\n",
    "results = play(random_player, random_player, N = 5,show_final_board=True)\n",
    "print(\"Blue (1) Wins:\",results[1])\n",
    "print(\"Red (-1) Wins:\",results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue (1) Wins: 356\n",
      "Red (-1) Wins: 644\n"
     ]
    }
   ],
   "source": [
    "# Run the random agents 1000 times and display the results.\n",
    "results = play(random_player, random_player, N = 1000,show_final_board=False)\n",
    "print(\"Blue (1) Wins:\",results[1])\n",
    "print(\"Red (-1) Wins:\",results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Minimax Search with Alpha-Beta Pruning [30 points]\n",
    "\n",
    "### Implement the search starting.\n",
    "\n",
    "Implement the search starting from a given board and specifying the player and put it into an agent function.\n",
    "You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
    "\n",
    "__Notes:__ \n",
    "* Make sure that all your agent functions have a signature consistent with the random agent above.\n",
    "* The search space for larger board may be too large. You can experiment with smaller boards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other(player): \n",
    "    if player == -1: return 1\n",
    "    else: return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "    \n",
    "# global variables\n",
    "DEBUG = 0 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "\n",
    "# Implementation of Minimax Search with Alpha Beta Pruning.\n",
    "# Adopted and modified from tictactoe_alpha_beta_tree_search.ipynb.\n",
    "def alpha_beta_search(board, player = 1, order_fun = None):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    value, move = max_value_ab(board, player, -math.inf, +math.inf, order_fun = order_fun)\n",
    "     \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched: {COUNT}\") \n",
    "    \n",
    "    return { \"move\": move, \"value\": value }\n",
    "\n",
    "def max_value_ab(state, player, alpha, beta, order_fun = None):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "       \n",
    "    # return utility if state is a terminal state\n",
    "    v = utility(state)\n",
    "    if DEBUG >= 2: print(\"max: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if terminal(state): return v, None\n",
    "        \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    possible_actions = actions(state)\n",
    "    \n",
    "    # Create a move ordering function, if one is supplied.\n",
    "    if order_fun is not None:\n",
    "        order_fun(possible_actions,state)\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in possible_actions:\n",
    "        v2, a2 = min_value_ab(result(state, a[0], a[1], a[2], other(player)), player, alpha, beta, order_fun = order_fun)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab(state, player, alpha, beta, order_fun = None):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility if state is a terminal state\n",
    "    v = utility(state)\n",
    "    if DEBUG >= 2: print(\"min: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if terminal(state): return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    possible_actions = actions(state)\n",
    "    \n",
    "    # Create a move ordering function, if one is supplied.\n",
    "    if order_fun is not None:\n",
    "        order_fun(possible_actions,state)\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in possible_actions:\n",
    "        v2, a2 = max_value_ab(result(state, a[0], a[1], a[2], other(player)), player, alpha, beta, order_fun = order_fun)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "def alpha_beta_search_player(board, player=None, order_fun=None):\n",
    "    return alpha_beta_search(board.copy(),player = player, order_fun=order_fun)[\"move\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player can claim a box and win\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player can avoid a C shape for the opponent\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player can fill a box and prevent a C shape\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player can create an L shape\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player can fill two boxes\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "boards = []\n",
    "for i in range(5):\n",
    "    boards.append({'n': 3,'m': 2})\n",
    "\n",
    "# Define board 0 lines.\n",
    "boards[0]['h',1,0] = True\n",
    "boards[0]['h',2,0] = True\n",
    "boards[0]['v',0,0] = True\n",
    "boards[0]['v',1,0] = True\n",
    "print('Player can claim a box and win')\n",
    "show_board(boards[0])\n",
    "\n",
    "# Define board 1 lines.\n",
    "boards[1]['v',0,0] = True\n",
    "boards[1]['h',1,0] = True\n",
    "print('Player can avoid a C shape for the opponent')\n",
    "show_board(boards[1])\n",
    "\n",
    "# Define board 2 lines.\n",
    "boards[2]['m'] = 3\n",
    "boards[2]['v',0,0] = True\n",
    "boards[2]['v',1,0] = True\n",
    "boards[2]['v',1,1] = True\n",
    "boards[2]['h',0,0] = True\n",
    "boards[2]['h',1,0] = True\n",
    "boards[2]['h',2,0] = True\n",
    "boards[2]['h',2,1] = True\n",
    "# Define board 2 box.\n",
    "boards[2][(1,0)] = -1\n",
    "print('Player can fill a box and prevent a C shape')\n",
    "show_board(boards[2])\n",
    "\n",
    "# Define board 3 lines.\n",
    "boards[3]['m'] = 3\n",
    "boards[3]['h',1,1] = True\n",
    "print('Player can create an L shape')\n",
    "show_board(boards[3])\n",
    "\n",
    "# Define board 4 lines.\n",
    "boards[4]['m'] = 3\n",
    "boards[4]['v',0,0] = True\n",
    "boards[4]['v',1,1] = True\n",
    "boards[4]['v',1,0] = True\n",
    "boards[4]['h',0,0] = True\n",
    "boards[4]['h',2,0] = True\n",
    "print('Player can fill two boxes')\n",
    "show_board(boards[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_player(player, pfun1, pfun2):\n",
    "    if player == 1:\n",
    "        return -1, pfun2\n",
    "    elif player == -1:\n",
    "        return 1, pfun1\n",
    "\n",
    "# Your code/ answer goes here.\n",
    "def test_move(fun, N = 1, show_res_board = False, start_board = empty_board(), order_fun = None, DEBUG = 0):\n",
    "    \"\"\"Run 'fun' N times on a given start_board. Return the ratio of optimal moves made to total moves made.\n",
    "    \n",
    "    Code Adopted and modified from tictactoe_interactive.ipynb.\n",
    "    \"\"\"\n",
    "\n",
    "    # Counts the number of optimal moves made in each of the N games.\n",
    "    # (We can run this N times if there's a stochastic element in pfun1).\n",
    "    optimal_cnt = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        init_board = start_board.copy()\n",
    "        player = 1\n",
    "        \n",
    "        if DEBUG >= 2: \n",
    "            print(\"For initial board:\")\n",
    "            show_board(init_board)\n",
    "\n",
    "        # Record the agent's action and utility.\n",
    "        action = fun(init_board, player, order_fun = order_fun)\n",
    "        board_with_move = result(init_board, action[0], action[1], action[2], player)\n",
    "        if DEBUG >= 2: print(\"Made move (\",action[0], action[1], action[2],\")\")\n",
    "        v = utility(board_with_move)\n",
    "\n",
    "        # Enumerate all possible actions and record their utilities, sorted in ascending order.\n",
    "        possible_actions = actions(init_board)\n",
    "\n",
    "        utilities = []\n",
    "\n",
    "        for a in possible_actions:\n",
    "            if DEBUG >= 1: print(\"Can place the line (\",a[0], a[1], a[2],\") with utility\",utility(result(init_board, a[0], a[1], a[2], player)))\n",
    "            utilities.append(utility(result(init_board, a[0], a[1], a[2], player)))\n",
    "        utilities.sort()\n",
    "\n",
    "        # Did the agent make an optimal move?\n",
    "        if v == utilities[-1]:\n",
    "            optimal_cnt += 1\n",
    "\n",
    "        # Show the move.\n",
    "        if (show_res_board): show_board(board_with_move) \n",
    "\n",
    "    return optimal_cnt / N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha beta tree search did not perform the optimal solution for Board 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD4CAYAAAAn3bdmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKpUlEQVR4nO3bwWuc+XnA8eeR9oV2qgw9rKFLEzDosLQEkYAIhZiwhB6q0EMPvhSsU2AO6iEx+gv6Bzim0JNhc1gIucwGAiE+5BBvEKRp5bAd2m4vcwgECusQ6kj4MnV/PVhd1l3Lmt2+M68e+fMBgS3//OoB/ebLT6/eydZaAFDDxtADALA80QYoRLQBChFtgEJEG6CQ11Zx0ddff71dv359FZcGuJIePnz4m9batYvWrSTa169fj+Pj41VcGuBKysxfLbPO7RGAQkQboBDRBihEtAEKEW2AQkQboBDRBihEtAEKEW2AQkQboBDRBihEtAEKEW2AQkQboBDRBihEtAEKEW2AQkQboBDRBihEtAEKEW2AQkQboBDRBihEtAEKEW2AQkQboBDRBihEtAEKEW2AQkQboBDRXoH5fB4HBwcxHo9jY2MjxuNxHBwcxHw+H3o0BmJP0JdsrfV+0d3d3XZ8fNz7dSu4f/9+3Lx5MxaLRSwWi48+33VddF0X0+k09vb2BpyQdbMnWEZmPmyt7V64TrT7M5/PY2dnJ548eXLumtFoFLPZLLa3t9c4GUOxJ1jWstF2e6RHd+7cee4k9SKLxSLu3r27pokYmj1B35y0ezQej+Pk5OTCdZubm3Hjxo01TMTQjo6O4unTpxeuG4/H8fjx4zVMxGXlpD2A09PTpdYt8yLmalj2e73s3oHXhh7gKtna2lrqpD0ej+PBgwerH4jBLfvT19bW1hqm4Spw0u7RrVu3ouu6l67pui729/fXNBFDsyfom2j36PDwcKkX6O3bt9c0EUOzJ+ibaPdoe3s7ptNpjEajT7xQu66L0WgU0+nUo12vEHuCvol2z/b29mI2m8VkMonNzc2IeHZfczKZxGw28yaKV9DH98TH3xFpT/BZeORvhd56662ICL90BC7kkT+AK0i0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENEGKES0AQoRbYBCRBugENFegfl8HgcHB3F0dBTvvfdejMfjODg4iPl8PvRoDOR/98R4PI6NjQ17gs8sW2u9X3R3d7cdHx/3ft0K7t+/Hzdv3ozFYhGLxeKjz3ddF13XxXQ6jb29vQEnZN3sCZaRmQ9ba7sXrrso2pn5hYh4JyL+KCL+OyLutdb+7mX/51WN9nw+j52dnXjy5Mm5a0ajUcxms9je3l7jZAzFnmBZy0Z7mdsj/xURh621P4mIP4uIv8nMP/3/DngV3blz57mT1IssFou4e/fumiZiaPYEffvUt0cy84cR8fettZ+ct+ZVPWmPx+M4OTm5cN3m5mbcuHFjDRMxtKOjo3j69OmF68bjcTx+/HgNE3FZ9XnS/vhFr0fElyPiFy/4t0lmHmfm8aNHjz7NZa+M09PTpdYt8yLmalj2e73s3oHXll2YmVsR8W5EfLu19rv/+++ttXsRcS/i2Um7twkL2draWuqkPR6P48GDB6sfiMEt+9PX1tbWGqbhKljqpJ2ZXTwL9vdaaz9Y7Uh13bp1K7que+marutif39/TRMxNHuCvl0Y7czMiHg7Ij5orX1n9SPVdXh4uNQL9Pbt22uaiKHZE/RtmZP2VyNiPyK+npnvn318Y8VzlbS9vR3T6TRGo9EnXqhd18VoNIrpdOrRrleIPUHfLox2a+2otZattZ3W2pfOPn68juEq2tvbi9lsFpPJ5Ll3v00mk5jNZt5E8QqyJ+iTd0QCXAIreeQPgGGJNkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWINkAhog1QiGgDFCLaAIWI9grM5/M4ODiI8XgcGxsbMR6P4+DgIObz+dCjMRB7gr5ka+3lCzK/GxF/GREftta+uMxFd3d32/HxcQ/j1XP//v24efNmLBaLWCwWH32+67roui6m02ns7e0NOCHrZk+wjMx82FrbvXDdEtH+WkScRsQ7ov1y8/k8dnZ24smTJ+euGY1GMZvNYnt7e42TMRR7gmUtG+0Lb4+01n4WEb/tZaor7s6dO8+dpF5ksVjE3bt31zQRQ7Mn6NuFJ+2IiMy8HhE/ctJ+ufF4HCcnJ0ute/z48RomYmj2BMvq7aT9Kb7gJDOPM/P40aNHfV22lNPT017XUZ89Qd96i3Zr7V5rbbe1tnvt2rW+LlvK1tZWr+uoz56gbx7569GtW7ei67qXrum6Lvb399c0EUOzJ+jbhdHOzO9HxM8j4s3M/HVmfnP1Y9V0eHi41Av09u3ba5qIodkT9G2Zp0f+urX2Rmuta619vrX29joGq2h7ezum02mMRqNPvFC7rovRaBTT6dSjXa8Qe4K+uT3Ss729vZjNZjGZTJ5799tkMonZbOZNFK8ge4I+LfXI36f1qj7yB/BZrf2RPwBWT7QBChFtgEJEG6AQ0QYoRLQBChFtgEJEG6AQ0QYoRLQBChFtgEJEG6AQ0QYoRLQBChFtgEJEG6AQ0QYoRLQBChFtgEJEG6AQ0QYoRLQBChFtgEJEG6AQ0QYoRLQBChFtgEJEG6AQ0QYoJFtr/V8081FE/Kr3C9f0ekT8ZughuFTsCV7kzdba5y5a9NoqvnJr7doqrltRZh631naHnoPLw57gRTLzeJl1bo8AFCLaAIWI9urdG3oALh17ghdZal+s5BeRAKyGkzZAIaINUIhor0BmfjczP8zMfxl6Fi6PzPxCZv40Mz/IzH/NzG8NPRPDy8zfy8x/zMx/PtsXf/vS9e5p9y8zvxYRpxHxTmvti0PPw+WQmW9ExButtV9m5uci4mFE/FVr7d8GHo0BZWZGxB+01k4zs4uIo4j4VmvtH1603kl7BVprP4uI3w49B5dLa+0/Wmu/PPvzSUR8EBF/POxUDK09c3r21+7s49zTtGjDADLzekR8OSJ+MfAoXAKZuZmZ70fEhxHxk9bauftCtGHNMnMrIt6NiG+31n439DwMr7X2tLX2pYj4fER8JTPPva0q2rBGZ/cs342I77XWfjD0PFwurbX/jIgHEfEX560RbViTs184vR0RH7TWvjP0PFwOmXktM//w7M+/HxF/HhH/ft560V6BzPx+RPw8It7MzF9n5jeHnolL4asRsR8RX8/M988+vjH0UAzujYj4aWbOIuKf4tk97R+dt9gjfwCFOGkDFCLaAIWINkAhog1QiGgDFCLaAIWINkAh/wOuTFGC6dE7qwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha beta tree search performed the optimal solution for Board 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha beta tree search performed the optimal solution for Board 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha beta tree search performed the optimal solution for Board 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAL8ElEQVR4nO3bT2ikhRnH8d+T8QV9nb542IUuVRqYgrQsQckgBRdZxIPx1GshOQlzmD2o7KFne0+D0F4WFBREKKNQkLl4MCsB/3QiOmj1sHMQhIIRMSbkMk2fHpI1293NzDub5H2fd+b7gYEs82b2gSf5zsubd8zdBQCIa67sAQAAoxFqAAiOUANAcIQaAIIj1AAQ3H1n8aLnzp3z+fn5s3hpAJhKm5ub37v7+bs9dyahnp+fV6/XO4uXBoCpZGbfHPcclz4AIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoc5hMBio3W4ryzLNzc0pyzK1220NBoOyR0MO7K/a2J8kdx/5kHS/pE8kfS7pS0kvj/uexcVFnxbdbtfTNPUkSVzSz48kSTxNU+92u2WPiBHYX7XN0v4k9fyYptrB88czM5P0oLvvmlkiaUPSC+7+0XHf02w2vdfrnewdJIDBYKCFhQXt7e0de0yapur3+2o0GgVOhjzYX7XN2v7MbNPdm3d7buylj8PY7x7+Mzl8jK77lFhdXdVwOBx5zHA41NraWkETYRLsr9rY35GxZ9SSZGY1SZuSfiPpb+7+p1HHT8sZdZZl2tnZGXtcrVbTpUuXCpgIk9jY2ND+/v7Y47Is0/b2dgETYRJ5f/+mZX8nOqOWJHffd/fHJD0s6Qkzu3iX/6RlZj0z621tbZ1o4Ch2d3fHHyTligGKl3cvefeMYuXdyyzs775JDnb3H81sXdKzkr647blrkq5JB2fUpzVgmer1eu539PX19bMfCBPJe0ZWr9cLmAaTyvv7Nwv7G3tGbWbnzeyhw68fkPSMpK/PeK4QlpeXlSTJyGOSJNHKykpBE2ES7K/a2N+RPHd9LEh6XVJNB2H/u7v/edT3TMs16ln7q/O0YX/VNmv7O+ldH313f9zdF9z94rhIT5NGo6FOp6M0Te94Z0+SRGmaqtPpTMUPyTRif9XG/o7wycQxlpaW1O/31Wq1VKvVJB1c+2y1Wur3+1paWip5QozC/qrt1v3d+snEWdtfrtvzJjUtlz5ud/nyZUniD4cVxf4Q2YlvzwMAlIdQA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhzmEwGKjdbmtjY0PXr19XlmVqt9saDAZlj4Yc2F+13dxflmWam5ubzf25+6k/FhcXfVp0u11P09STJHFJPz+SJPE0Tb3b7ZY9IkZgf9U2S/uT1PNjmmoHzx/PzB6R9IakX0r6r6Rr7v7KqO9pNpve6/VO+BZSvsFgoIWFBe3t7R17TJqm6vf7ajQaBU6GPNhftc3a/sxs092bd3suz6WP/0i66u6/lfR7SVfM7HenOWBUq6urGg6HI48ZDodaW1sraCJMgv1VG/s7MvaM+o5vMPuHpL+6+3vHHTMtZ9RZlmlnZyfXcdvb2wVMhEmwv2qbtf2d9Iz61heal/S4pI/v8lzLzHpm1tva2rqnQaPZ3d091eNQLPZXbezvSO5Qm1ld0tuSXnT3n25/3t2vuXvT3Zvnz58/zRlLU6/XT/U4FIv9VRv7O5Ir1GaW6CDSb7r7O2c7UhzLy8tKkmTkMUmSaGVlpaCJMAn2V23s70ieuz5M0uuSfnD3F/O86LRco561vzpPG/ZXbbO2v5Neo35S0oqkp83ss8PHc6c6YVCNRkOdTkdpmt7xzp4kidI0VafTmYofkmnE/qqN/d3iuBusT/KYpg+8uLvfuHHDr1y54rVazSV5lmV+5coVv3HjRtmjIQf2V20395dlmc/NzU3t/nSSD7zci2m59HG7y5cvS5LW19dLnQP3hv0hslO7PQ8AUDxCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9Q5DAYDtdttbWxs6Pr168qyTO12W4PBoOzRkAP7q7ab+8uyTHNzc7O5P3cf+ZD0mqTvJH0x7tibj8XFRZ8W3W7X0zT1JElc0s+PJEk8TVPvdrtlj4gR2F+1zdL+JPX8mKbawfPHM7OnJO1KesPdL+aJf7PZ9F6vd09vHJEMBgMtLCxob2/v2GPSNFW/31ej0ShwMuTB/qpt1vZnZpvu3rzbc2Mvfbj7B5J+OPWpKmB1dVXD4XDkMcPhUGtrawVNhEmwv2pjf0fGnlFLkpnNS3p31s6osyzTzs7O2ONqtZouXbpUwESYxMbGhvb398cel2WZtre3C5gIk8j7+zct+zvRGfUE/0nLzHpm1tva2jqtly3V7u5uruPyxADFy7uXvHtGsfLuZRb2d99pvZC7X5N0TTo4oz6t1y1TvV7P/Y6+vr5+9gNhInnPyOr1egHTYFJ5f/9mYX/cnjfC8vKykiQZeUySJFpZWSloIkyC/VUb+zsyNtRm9pakDyU9ambfmtnzZz9WDFevXs31g/LSSy8VNBEmwf6qjf0dyXPXxx/d/YK7J+7+sLu/WsRgETQaDXU6HaVpescPTJIkStNUnU5nKm4Nmkbsr9rY3xEufYyxtLSkfr+vVqv1f5+MarVa6vf7WlpaKntEjMD+qo39Hch1e96kpuX2PAAoSiG35wEAzgahBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwZm7n/6Lmm1J+ubUXziGc5K+L3sI3DP2V23TvL9fu/v5uz1xJqGeZmbWc/dm2XPg3rC/apvV/XHpAwCCI9QAEByhnty1sgfAibC/apvJ/XGNGgCC44waAIIj1AAQHKHOycxeM7PvzOyLsmfB5MzsETN738y+MrMvzeyFsmdCPmZ2v5l9YmafH+7u5bJnKhrXqHMys6ck7Up6w90vlj0PJmNmFyRdcPdPzewXkjYl/cHd/1XyaBjDzEzSg+6+a2aJpA1JL7j7RyWPVhjOqHNy9w8k/VD2HLg37v5vd//08OsdSV9J+lW5UyEPP7B7+M/k8DFTZ5iEGjPHzOYlPS7p45JHQU5mVjOzzyR9J+k9d5+p3RFqzBQzq0t6W9KL7v5T2fMgH3ffd/fHJD0s6Qkzm6nLj4QaM+Pw+ubbkt5093fKngeTc/cfJa1LerbcSYpFqDETDv8g9aqkr9z9L2XPg/zM7LyZPXT49QOSnpH0dalDFYxQ52Rmb0n6UNKjZvatmT1f9kyYyJOSViQ9bWafHT6eK3so5HJB0vtm1pf0Tx1co3635JkKxe15ABAcZ9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcP8D23UI3nOdGMMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha beta tree search did not perform the optimal solution for Board 4\n"
     ]
    }
   ],
   "source": [
    "# Run the agent on each.\n",
    "for i, curr_board in enumerate(boards):\n",
    "    is_optimal = test_move(alpha_beta_search_player, start_board=curr_board, show_res_board=True)\n",
    "    if (is_optimal >= 0.995):\n",
    "        print(\"Alpha beta tree search performed the optimal solution for Board\",i)\n",
    "    else:\n",
    "        print(\"Alpha beta tree search did not perform the optimal solution for Board\",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board make the board larger. What is the largest board you can solve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (2, 2) board took 0.00200 seconds to make a move 10 times.\n",
      "A (2, 3) board took 0.04300 seconds to make a move 10 times.\n",
      "A (3, 3) board took 13.08093 seconds to make a move 10 times.\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "# Your code/ answer goes here.\n",
    "board_sizes = [(2,2),(2,3),(3,3)]\n",
    "\n",
    "# FIXME: Insufferably long move times for any board of size > 3x3. Is that expected?\n",
    "for board_size in board_sizes:\n",
    "    t_i = time.time()\n",
    "    test_move(alpha_beta_search_player,start_board=empty_board(board_size[0],board_size[1]), N=10)\n",
    "    t_f = time.time()\n",
    "    print(\"A %s board took %.5f seconds to make a move 10 times.\" % (board_size,t_f-t_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering\n",
    "\n",
    "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "# Move ordering strategy -- does my move create a new box?\n",
    "def move_ordering_1(possible_moves, board):\n",
    "\n",
    "    boxes_difference = lambda move: len(get_boxes(result(board, move[0], move[1], move[2], player = 1))) - len(get_boxes(board))\n",
    "\n",
    "    possible_moves.sort(key=boxes_difference)\n",
    "\n",
    "# Move ordering strategy -- is my move as close to the center of the board as possible (rounded down)?\n",
    "# We introduce both ordering functions because both would appear to be effective, but for testing a single move on an empty board,\n",
    "# only move_ordering_2 would produce any actual ordering (Since producing a box on an empty board with 1 move is impossible).\n",
    "def move_ordering_2(possible_moves, board):\n",
    "\n",
    "    n = board['n']\n",
    "    m = board['m']\n",
    "\n",
    "    n_center =  n // 2\n",
    "    m_center = m // 2\n",
    "\n",
    "    pos_difference = lambda move: abs(move[1] - n_center) + abs(move[2] - m_center)\n",
    "\n",
    "    possible_moves.sort(key=pos_difference)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (2, 2) board took 0.00100 seconds to make a move 10 times.\n",
      "A (2, 3) board took 0.06000 seconds to make a move 10 times.\n"
     ]
    }
   ],
   "source": [
    "for board_size in board_sizes:\n",
    "    t_i = time.time()\n",
    "    test_move(alpha_beta_search_player,start_board=empty_board(board_size[0],board_size[1]), order_fun=move_ordering_2, N=10)\n",
    "    t_f = time.time()\n",
    "    print(\"A %s board took %.5f seconds to make a move 10 times.\" % (board_size,t_f-t_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time in seconds for Alpha Beta Tree search to make a move (repeated 10 times).\n",
    "No Move Ordering vs Move Ordering (using the Move Ordering 2 strategy) are compared.\n",
    "\n",
    "| Size     | No Move Ordering |  With Move Ordering |\n",
    "|----------|------------------|---------------------|\n",
    "| 2x2     | 0.001 s | 0.002 s |\n",
    "| 2x3   | 0.045 s | 0.066 s |\n",
    "| 3x3 | 13.94 s | 10.69 s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first few moves\n",
    "\n",
    "Start with an empty board. This is the worst case scenario for minimax search with alpha-beta pruning since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue (1) Wins: 3\n",
      "Red (-1) Wins: 1\n",
      "Draws: 6\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "results = play(alpha_beta_search_player, random_player, N = 10,show_final_board=False,start_board=empty_board(3,3))\n",
    "print(\"Blue (1) Wins:\",results[1])\n",
    "print(\"Red (-1) Wins:\",results[-1])\n",
    "print(\"Draws:\",results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search [30 points] \n",
    "\n",
    "### Heuristic evaluation function\n",
    "\n",
    "Define and implement a heuristic evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_C_shapes(board):\n",
    "    \"\"\"Given all sets of \"boxes\" in the board,\n",
    "    return now many boxes form C shapes.\"\"\"\n",
    "\n",
    "    n = board['n'] # Number of rows\n",
    "    m = board['m'] # Number of columns\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for row in range(n):\n",
    "        for col in range(n):\n",
    "            num_lines = 0\n",
    "\n",
    "            # Checks the 4 lines that form a box\n",
    "            if ('h',row,col) in board: num_lines +=1\n",
    "            if ('v',row,col) in board: num_lines +=1\n",
    "            if ('h',row+1,col) in board: num_lines +=1\n",
    "            if ('v',row,col+1) in board: num_lines +=1\n",
    "\n",
    "            if (num_lines == 3): \n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "def count_L_II_shapes(board):\n",
    "    \"\"\"Given all sets of \"boxes\" in the board,\n",
    "    return now many boxes form L shapes or\n",
    "    parallel line (||) shapes.\"\"\"\n",
    "\n",
    "    n = board['n'] # Number of rows\n",
    "    m = board['m'] # Number of columns\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    # For each dot in the board (representing top left of a box...)\n",
    "    for row in range(n):\n",
    "        for col in range(n):\n",
    "            num_lines = 0\n",
    "\n",
    "            # Checks the 4 lines that form a box\n",
    "            for h in [(0,'h'),(1,'v')]:\n",
    "                for v in [0,1]:\n",
    "                    # FIXME: PROBABLY COMPLETELY WRONG\n",
    "                    if (h[1],row+h[0],col+v) in board: num_lines +=1\n",
    "\n",
    "            if (num_lines == 2): \n",
    "                count += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "def eval_fun(board, player = 1, w1 = 3, w2 = 2, w3 = 1):\n",
    "    \"\"\"heuristic for utility of state. Returns score for a node:\n",
    "    1. For terminal states it returns the utility. \n",
    "    2. For non-terminal states, it calculates a weighted linear function using 2 features of the state:\n",
    "    - How many C shapes are found. C shapes boost utility.\n",
    "    - How many 'boxes' have 2 lines filled out (L shapes, or parallel lines). These shapes reduce utility.\n",
    "    - Weighted based on current utility (Boxes owned by max vs Boxes owned by min).\n",
    "\n",
    "    We need to be careful that the utility of the heuristic stays between [-1,1]. \n",
    "    Note that the largest possible number of these positions is 4. I weigh the count by 0.1, \n",
    "    guaranteeing that is in the needed range.\n",
    "    \n",
    "    Adopted and Modified from tictactoe_heuristic_alpha_beta_tree_search.ipynb.\n",
    "\n",
    "    Function Returns: heuistic value, terminal?\"\"\"\n",
    "    # terminal state?\n",
    "    u = utility(board)\n",
    "    if terminal(board): return u, True\n",
    "    \n",
    "    # Determine Heuristic value.\n",
    "    # w1, w2, and w3 modify functional components of the evaluation function.\n",
    "    #   w1 - C shapes\n",
    "    #   w2 - L shapes or parallel lines\n",
    "    #   w3 - Current utility of this board\n",
    "    score = (3 * count_C_shapes(board) - 2 * count_L_II_shapes(board)) + (w3 * u)\n",
    "    \n",
    "    return score, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting off search \n",
    "\n",
    "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "import math\n",
    "    \n",
    "# global variables\n",
    "DEBUG = 0 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "\n",
    "# Implementation of Minimax Search with Alpha Beta Pruning.\n",
    "# Adopted and modified from tictactoe_alpha_beta_tree_search.ipynb.\n",
    "def heuristic_ab_search(board, player = 1, cutoff = None):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    value, move = heuristic_max_value_ab(board, player, -math.inf, +math.inf, 0, cutoff)\n",
    "     \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched: {COUNT}\") \n",
    "    \n",
    "    return { \"move\": move, \"value\": value }\n",
    "\n",
    "def heuristic_max_value_ab(state, player, alpha, beta, depth, cutoff):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "       \n",
    "    # cut off and terminal test\n",
    "    v, terminal = eval_fun(state, player)\n",
    "    if((cutoff is not None and depth >= cutoff) or terminal): \n",
    "        if(terminal): \n",
    "            alpha, beta = v, v\n",
    "        if DEBUG >= 2: print(f\"stopped at {depth}: {state} term: {terminal} eval: {v} [{alpha}, {beta}]\" ) \n",
    "        return v, None\n",
    "    \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = heuristic_min_value_ab(result(state, a[0], a[1], a[2], other(player)), player, alpha, beta, depth+1, cutoff)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def heuristic_min_value_ab(state, player, alpha, beta, depth, cutoff):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # cut off and terminal test\n",
    "    v, terminal = eval_fun(state, player)\n",
    "    if((cutoff is not None and depth >= cutoff) or terminal): \n",
    "        if(terminal): \n",
    "            alpha, beta = v, v\n",
    "        if DEBUG >= 2: print(f\"stopped at {depth}: {state} term: {terminal} eval: {v} [{alpha}, {beta}]\" ) \n",
    "        return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = heuristic_max_value_ab(result(state, a[0], a[1], a[2], other(player)), player, alpha, beta, depth+1, cutoff)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "def heuristic_ab_search_player(board, player=None, order_fun = None):\n",
    "    return heuristic_ab_search(board.copy(),player = player)[\"move\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the same manually created boards as above to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_C_shapes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18752/3397191985.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run the agent on each.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurr_board\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mis_optimal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheuristic_ab_search_player\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_board\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_board\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_res_board\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Heuristic Alpha beta tree search performed the optimal solution for Board\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18752/3904082707.py\u001b[0m in \u001b[0;36mtest_move\u001b[1;34m(fun, N, show_res_board, start_board, order_fun, DEBUG)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# Record the agent's action and utility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_board\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder_fun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morder_fun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mboard_with_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_board\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Made move (\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\")\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18752/1699609033.py\u001b[0m in \u001b[0;36mheuristic_ab_search_player\u001b[1;34m(board, player, order_fun)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Your code/ answer goes here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mheuristic_ab_search_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder_fun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mheuristic_ab_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"move\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18752/1727881911.py\u001b[0m in \u001b[0;36mheuristic_ab_search\u001b[1;34m(board, player, cutoff)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mCOUNT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_max_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Number of nodes searched: {COUNT}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18752/1727881911.py\u001b[0m in \u001b[0;36mheuristic_max_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# cut off and terminal test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcutoff\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mterminal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterminal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18752/2714845473.py\u001b[0m in \u001b[0;36meval_fun\u001b[1;34m(board, player, w1, w2, w3)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m#   w2 - L shapes or parallel lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m#   w3 - Current utility of this board\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcount_C_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcount_L_II_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_C_shapes' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the agent on each.\n",
    "for i, curr_board in enumerate(boards):\n",
    "    is_optimal = test_move(heuristic_ab_search_player, start_board=curr_board, show_res_board=True)\n",
    "    print(\"Heuristic Alpha beta tree search performed the optimal solution for Board\",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (3, 3) board took 2.41586 seconds to make a move.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/2158321488.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mboard_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mboard_sizes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mt_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtest_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheuristic_ab_search_player\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart_board\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mempty_board\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mboard_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mt_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"A %s board took %.5f seconds to make a move.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mboard_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_f\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/420768624.py\u001b[0m in \u001b[0;36mtest_move\u001b[1;34m(fun, N, show_res_board, start_board)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Record the agent's action and utility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1544406405.py\u001b[0m in \u001b[0;36mheuristic_ab_search_player\u001b[1;34m(board, player)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Your code/ answer goes here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mheuristic_ab_search_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mheuristic_ab_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"move\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_ab_search\u001b[1;34m(board, player, cutoff)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mCOUNT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_max_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Number of nodes searched: {COUNT}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_max_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_min_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_min_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_max_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_max_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_min_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_min_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_max_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_max_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_min_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_min_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_max_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_max_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_min_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_min_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_max_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_max_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_min_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_min_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_max_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_max_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_min_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_min_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_max_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_max_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_min_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_min_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_max_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_max_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic_min_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/1727881911.py\u001b[0m in \u001b[0;36mheuristic_min_value_ab\u001b[1;34m(state, player, alpha, beta, depth, cutoff)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# cut off and terminal test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcutoff\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mterminal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterminal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/319918025.py\u001b[0m in \u001b[0;36meval_fun\u001b[1;34m(board, player)\u001b[0m\n\u001b[0;32m     16\u001b[0m     Function Returns: heuistic value, terminal?\"\"\"\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# terminal state?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mterminal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/226842189.py\u001b[0m in \u001b[0;36mutility\u001b[1;34m(board)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Who owns what box?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Calculate utility by calculating Max - Min.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbox\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbox\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mutility\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1656/139817954.py\u001b[0m in \u001b[0;36mget_boxes\u001b[1;34m(board)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mboxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "import time \n",
    "\n",
    "# Your code/ answer goes here.\n",
    "board_sizes = [(3,3),(3,4),(3,5),(3,6),(3,7)]\n",
    "\n",
    "# FIXME: Insufferably long move times for any board of size > 3x3. Is that expected?\n",
    "for board_size in board_sizes:\n",
    "    t_i = time.time()\n",
    "    test_move(heuristic_ab_search_player,start_board=empty_board(board_size[0],board_size[1]))\n",
    "    t_f = time.time()\n",
    "    print(\"A %s board took %.5f seconds to make a move.\" % (board_size,t_f-t_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tournament task [+1 to 5% bonus on your course grade; will be assigned separately]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. You are allowed to use any improvements you like as long as you code it yourself. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 Bonus point].\n",
    "\n",
    "### Pure Monte Carlo Search\n",
    "\n",
    "Implement Pure Monte Carlo Search (see [tic-tac-toe-example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_pure_monte_carlo_search.ipynb)) and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "How would you determine what the best first move for a standard board ($5 \\times 5$) is? You can use Pure Monte Carlo Search or any algorithms that you have implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
